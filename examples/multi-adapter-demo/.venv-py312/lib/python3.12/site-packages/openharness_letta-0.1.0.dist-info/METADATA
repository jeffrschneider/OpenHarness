Metadata-Version: 2.4
Name: openharness-letta
Version: 0.1.0
Summary: Open Harness adapter for Letta (formerly MemGPT)
Project-URL: Homepage, https://github.com/openharness/openharness
Project-URL: Documentation, https://openharness.github.io/openharness
Project-URL: Repository, https://github.com/openharness/openharness
Author: Open Harness Contributors
License-Expression: MIT
Keywords: ai-agents,letta,llm,memgpt,openharness
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Requires-Dist: letta-client>=0.1.0
Requires-Dist: openharness>=0.1.0
Provides-Extra: dev
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Requires-Dist: ruff>=0.1.0; extra == 'dev'
Description-Content-Type: text/markdown

# OpenHarness Letta Adapter

Open Harness adapter for [Letta](https://www.letta.com/) (formerly MemGPT), a framework for building stateful LLM agents with persistent memory.

## Installation

```bash
pip install openharness-letta
```

## Quick Start

```python
from openharness_letta import LettaAdapter, MemoryBlockManager
from openharness_letta.types import LettaAgentConfig, MemoryBlock

# Connect to Letta cloud
adapter = LettaAdapter(api_key="letta-...")

# Or connect to local Letta server
adapter = LettaAdapter(base_url="http://localhost:8283")

# Create an agent with memory
agent_id = await adapter.create_agent(LettaAgentConfig(
    name="my-assistant",
    model="openai/gpt-4o-mini",
    memory_blocks=[
        MemoryBlock(label="human", value="Name: Alice\nPreferences: Detailed explanations"),
        MemoryBlock(label="persona", value="I am a helpful coding assistant."),
    ],
))

# Execute a prompt
from openharness.types import ExecuteRequest

result = await adapter.execute(
    ExecuteRequest(message="Hello! Can you help me with Python?", agent_id=agent_id)
)
print(result.output)
```

## Streaming Execution

```python
from openharness.types import ExecuteRequest

async for event in adapter.execute_stream(
    ExecuteRequest(message="Explain recursion step by step", agent_id=agent_id)
):
    if event.type == "text":
        print(event.content, end="")
    elif event.type == "thinking":
        print(f"[Thinking: {event.thinking}]")
    elif event.type == "tool_call_start":
        print(f"\n[Tool: {event.name}]")
```

## Memory Management

Letta's unique feature is persistent memory blocks that survive across conversations. The adapter provides full access to this capability:

```python
# Get memory manager
memory = adapter.memory

# View current memory blocks
blocks = await memory.get_blocks(agent_id)
for block in blocks:
    print(f"{block.label}: {block.value[:50]}...")

# Update a memory block
await memory.update_block(
    agent_id,
    "human",
    "Name: Alice\nPreferences: Concise responses\nExpertise: Python, TypeScript"
)

# Add a new memory block
await memory.add_block(
    agent_id,
    MemoryBlock(
        label="project",
        value="Working on OpenHarness - a universal API for AI harnesses"
    )
)
```

## Capability Matrix

| Capability | Supported | Notes |
|------------|-----------|-------|
| agents.create | ✅ | Full support with memory blocks |
| agents.get | ✅ | |
| agents.list | ✅ | |
| agents.update | ✅ | |
| agents.delete | ✅ | |
| execution.run | ✅ | |
| execution.stream | ✅ | |
| sessions.* | ❌ | Letta uses agents for state |
| memory.blocks.* | ✅ | Letta's core feature |
| memory.archive.* | ✅ | Semantic search in archival memory |
| mcp.* | ❌ | |
| files.* | ❌ | |
| hooks.* | ❌ | |
| tools.list | ✅ | |
| tools.register | ✅ | Custom tool registration |

## Letta-Specific Features

### Memory Blocks

Letta agents have persistent memory organized into "blocks":

- **human**: Information about the user
- **persona**: The agent's personality and instructions
- **Custom blocks**: Any additional context you want to persist

The agent can read and write to these blocks during conversations, allowing it to remember information across sessions.

### Inner Monologue

Letta agents have an "inner monologue" - their thinking process is visible and can be included in streaming:

```python
async for event in adapter.execute_stream(request, include_thinking=True):
    if event.type == "thinking":
        print(f"Agent is thinking: {event.thinking}")
```

### Archival Memory

For long-term storage beyond the context window, Letta provides archival memory with semantic search:

```python
# Search archival memory (when implemented)
results = await adapter.search_archive(
    agent_id,
    query="previous conversation about Python decorators",
    limit=5
)
```

## Configuration

### Environment Variables

- `LETTA_API_KEY` - Letta cloud API key

### Adapter Options

```python
adapter = LettaAdapter(
    api_key="letta-...",       # Letta cloud API key
    base_url="http://...",     # Local server URL (alternative to api_key)
    timeout=60.0,              # Request timeout in seconds
)
```

## Running Letta Locally

To run Letta locally for development:

```bash
# Install Letta server
pip install letta

# Start the server
letta server
```

The server will start at `http://localhost:8283` by default.

## License

MIT
