Metadata-Version: 2.4
Name: openharness-deepagent
Version: 0.1.0
Summary: Open Harness adapter for LangChain Deep Agents
Project-URL: Homepage, https://github.com/openharness/openharness
Project-URL: Documentation, https://openharness.github.io/openharness
Project-URL: Repository, https://github.com/openharness/openharness
Author: Open Harness Contributors
License-Expression: MIT
Keywords: ai-agents,deepagents,langchain,langgraph,llm,openharness
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.11
Requires-Dist: deepagents>=0.3.0
Requires-Dist: openharness>=0.1.0
Provides-Extra: dev
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Requires-Dist: ruff>=0.1.0; extra == 'dev'
Provides-Extra: mcp
Requires-Dist: langchain-mcp-adapters>=0.1.0; extra == 'mcp'
Description-Content-Type: text/markdown

# OpenHarness Deep Agent Adapter

Open Harness adapter for [LangChain Deep Agents](https://github.com/langchain-ai/deepagents), sophisticated AI agents with planning, subagents, and file system capabilities.

## Installation

```bash
pip install openharness-deepagent

# With MCP support
pip install openharness-deepagent[mcp]
```

**Note:** Deep Agents requires Python 3.11+.

## Quick Start

```python
from openharness_deepagent import DeepAgentAdapter
from openharness_deepagent.types import DeepAgentConfig
from openharness.types import ExecuteRequest

# Create adapter with default configuration
adapter = DeepAgentAdapter()

# Or with custom configuration
adapter = DeepAgentAdapter(DeepAgentConfig(
    model="anthropic:claude-sonnet-4-5-20250929",
    system_prompt="You are an expert researcher and analyst.",
))

# Execute a prompt
result = await adapter.execute(
    ExecuteRequest(message="Research the latest trends in AI agents")
)
print(result.output)
```

## Streaming Execution

```python
from openharness.types import ExecuteRequest

async for event in adapter.execute_stream(
    ExecuteRequest(message="Write a Python script to analyze data")
):
    if event.type == "text":
        print(event.content, end="")
    elif event.type == "thinking":
        print(f"[Thinking: {event.thinking}]")
    elif event.type == "tool_call_start":
        print(f"\n[Tool: {event.name}]")
    elif event.type == "tool_result":
        print(f"[Result: {event.output}]")
    elif event.type == "progress":
        print(f"[Progress: {event.step}]")
    elif event.type == "done":
        print("\n[Complete]")
```

## Planning with Todos

Deep Agents include built-in planning tools for task decomposition:

```python
from openharness_deepagent.types import DeepAgentConfig

adapter = DeepAgentAdapter(DeepAgentConfig(
    system_prompt="""
    You are a methodical researcher. For complex tasks:
    1. Use write_todos to create a task list
    2. Work through each task systematically
    3. Update todos as you complete them
    """
))

# The agent will automatically use write_todos and read_todos
result = await adapter.execute(
    ExecuteRequest(message="Research and summarize the top 5 AI frameworks")
)
```

### Built-in Planning Tools

| Tool | Description |
|------|-------------|
| `write_todos` | Create or update task lists |
| `read_todos` | View current task list |

## Subagents

Delegate specialized work to subagents for context isolation:

```python
from openharness_deepagent.types import DeepAgentConfig, SubagentConfig

adapter = DeepAgentAdapter(DeepAgentConfig(
    model="anthropic:claude-sonnet-4-5-20250929",
    subagents=[
        SubagentConfig(
            name="code-reviewer",
            description="Reviews code for bugs, security issues, and improvements",
            system_prompt="You are an expert code reviewer.",
        ),
        SubagentConfig(
            name="researcher",
            description="Performs in-depth research on technical topics",
            system_prompt="You are an expert technical researcher.",
            model="openai:gpt-4o",  # Can use different model
        ),
    ],
))

# Agent can delegate to subagents using the task tool
result = await adapter.execute(
    ExecuteRequest(message="Review this code and research best practices for improvement")
)
```

## File System Operations

Deep Agents have built-in file system tools:

```python
from openharness_deepagent.types import DeepAgentConfig, BackendType

# Use filesystem backend for real disk access
adapter = DeepAgentAdapter(DeepAgentConfig(
    backend_type=BackendType.FILESYSTEM,
    backend_root_dir="/path/to/workspace",
))

# Agent can now use file tools
result = await adapter.execute(
    ExecuteRequest(message="Read the README.md file and summarize it")
)
```

### Built-in File Tools

| Tool | Description |
|------|-------------|
| `ls` | List directory contents |
| `read_file` | Read file with optional pagination |
| `write_file` | Create or overwrite files |
| `edit_file` | Edit with exact string replacements |
| `glob` | Find files matching patterns |
| `grep` | Search text patterns in files |
| `execute` | Run sandboxed shell commands |

### File Backends

| Backend | Description |
|---------|-------------|
| `STATE` | Ephemeral, in-memory (default) |
| `FILESYSTEM` | Real disk access |
| `STORE` | Persistent via LangGraph Store |
| `COMPOSITE` | Route paths to different backends |

## Custom Tools

Register custom tools with your agent:

```python
def internet_search(query: str, max_results: int = 5) -> str:
    """Search the internet for information.

    Args:
        query: Search query
        max_results: Maximum results to return
    """
    # Your search implementation
    return f"Results for: {query}"

adapter = DeepAgentAdapter(
    config=DeepAgentConfig(
        system_prompt="You can search the internet for information.",
    ),
    tools=[internet_search],
)
```

## MCP Integration

Use MCP tools via the langchain-mcp-adapters library:

```python
from langchain_mcp_adapters import create_mcp_tools

# Create MCP tools
mcp_tools = create_mcp_tools(
    server_command=["npx", "-y", "@anthropic-ai/mcp-server-filesystem", "/tmp"]
)

adapter = DeepAgentAdapter(
    config=DeepAgentConfig(),
    tools=mcp_tools,
)

# Use async invocation with MCP tools
result = await adapter.execute(
    ExecuteRequest(message="List files in the temp directory")
)
```

## Capability Matrix

| Capability | Supported | Notes |
|------------|-----------|-------|
| execution.run | ✅ | Sync execution |
| execution.stream | ✅ | Async streaming |
| planning.todos | ✅ | write_todos, read_todos |
| subagents.spawn | ✅ | Via task tool |
| subagents.delegate | ✅ | Context isolation |
| files.read | ✅ | read_file tool |
| files.write | ✅ | write_file tool |
| files.list | ✅ | ls tool |
| files.search | ✅ | glob, grep tools |
| tools.list | ✅ | |
| tools.register | ✅ | Before init |
| mcp.tools | ✅ | Via langchain-mcp-adapters |
| models.switch | ✅ | Any LangChain model |
| sessions.* | ❌ | Stateless by default |
| agents.* | ❌ | Uses invocation model |
| hooks.* | ❌ | Use middleware instead |

## Configuration

### DeepAgentConfig Options

```python
from openharness_deepagent.types import (
    DeepAgentConfig,
    SubagentConfig,
    BackendType,
    InterruptConfig,
)

config = DeepAgentConfig(
    # Model selection (default: claude-sonnet-4-5-20250929)
    model="anthropic:claude-sonnet-4-5-20250929",

    # Custom system prompt (appends to default)
    system_prompt="You are an expert assistant.",

    # Custom tools
    tools=[my_tool_function],

    # Subagent configurations
    subagents=[
        SubagentConfig(
            name="researcher",
            description="Research specialist",
            system_prompt="Expert researcher",
        ),
    ],

    # File backend
    backend_type=BackendType.FILESYSTEM,
    backend_root_dir="/workspace",

    # Human-in-the-loop interrupts
    interrupt_on=[
        InterruptConfig(
            tool_name="execute",
            allowed_decisions=["approve", "reject"],
        ),
    ],

    # Custom middleware
    middleware=[],
)
```

### Supported Models

Deep Agents supports any LangChain model:

```python
# Anthropic (default)
model="anthropic:claude-sonnet-4-5-20250929"
model="anthropic:claude-opus-4-20250514"

# OpenAI
model="openai:gpt-4o"
model="openai:gpt-4o-mini"

# Google
model="google:gemini-1.5-pro"

# Local via Ollama
model="ollama:llama3.2"

# Or pass a LangChain model object
from langchain_openai import ChatOpenAI
adapter = DeepAgentAdapter(DeepAgentConfig(
    model=ChatOpenAI(model="gpt-4o"),
))
```

## Deep Agent Features

### Task Decomposition

Deep Agents excel at breaking down complex tasks:

```python
result = await adapter.execute(ExecuteRequest(
    message="""
    Create a complete Python project with:
    1. A CLI tool for data processing
    2. Unit tests
    3. Documentation
    4. Setup.py for packaging
    """
))
```

### Context Management

Files help manage large contexts:

```python
# Agent can offload information to files
result = await adapter.execute(ExecuteRequest(
    message="Research this large codebase and create a summary in /analysis/summary.md"
))
```

### Sandboxed Execution

The `execute` tool runs shell commands in a sandbox:

```python
result = await adapter.execute(ExecuteRequest(
    message="Run the test suite and fix any failing tests"
))
```

## License

MIT
